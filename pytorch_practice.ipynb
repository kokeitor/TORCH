{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JVQ13l32QpB",
        "outputId": "79961510-ee34-4c42-8373-8bfb55d03ed4"
      },
      "outputs": [],
      "source": [
        "# Esto es solo para poder debugear.\n",
        "#!pip install torch tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "# Genera una semilla fija para que los experimentos sea repetibles.\n",
        "t_cg = torch.manual_seed(1547)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MbJDaOcZGIr"
      },
      "source": [
        "### NUMPY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "k40zE64ZUegJ"
      },
      "outputs": [],
      "source": [
        "x = np.array([[1, 2,3, 4]],dtype = np.float32)\n",
        "y = np.array([2, 4,6,8], dtype = np.float32)\n",
        "\n",
        "def forward(x):\n",
        "  return x * w\n",
        "def loss(y_pred, y):\n",
        "  return np.mean(((y_pred - y)**2))\n",
        "\n",
        "def grad(y_pred,y):\n",
        "  return (x* 2 * ((y_pred) - y)).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5ayDy4JU3Q9",
        "outputId": "a608d9bd-16f8-47aa-af7d-dd44502c2683"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30.0 1.5\n",
            "1.875 1.875\n",
            "0.1171875 1.96875\n",
            "0.0073242188 1.9921875\n",
            "0.00045776367 1.998046875\n",
            "2.861023e-05 1.99951171875\n",
            "1.7881393e-06 1.9998779296875\n",
            "1.1175871e-07 1.999969482421875\n",
            "6.9849193e-09 1.9999923706054688\n",
            "4.3655746e-10 1.9999980926513672\n",
            "9.999990463256836\n"
          ]
        }
      ],
      "source": [
        "w= 0.0\n",
        "lr =0.05\n",
        "for e in range(10):\n",
        "  y_pred = forward(x)\n",
        "  loss_i = loss(y_pred,y)\n",
        "  grad_i = grad(y_pred,y)\n",
        "  w -= lr*grad_i\n",
        "  print(loss_i, w)\n",
        "\n",
        "print(forward(x = 5))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1RouJqWZHQ3"
      },
      "source": [
        "### TORCH METHOD 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZEedSeCoZFT4"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor([1,2,3, 4],dtype = torch.float32, requires_grad = False)\n",
        "y = torch.tensor([2,4,6,8], dtype = torch.float32, requires_grad = False)\n",
        "w = torch.tensor(0.0,dtype = torch.float32, requires_grad = True)\n",
        "\n",
        "\n",
        "def forward(x):\n",
        "  return w *  x\n",
        "def loss(y_pred, y):\n",
        "  return ((y_pred - y)**2).mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPV0BhWwhbaS",
        "outputId": "9f3b845e-e48e-4a47-ee54-adad8f82c58e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:00<00:00, 1786.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 0\n",
            "loss : 30.000\n",
            "w : 0.300\n",
            "epoch : 10\n",
            "loss : 1.163\n",
            "w : 1.665\n",
            "epoch : 20\n",
            "loss : 0.045\n",
            "w : 1.934\n",
            "epoch : 30\n",
            "loss : 0.002\n",
            "w : 1.987\n",
            "epoch : 40\n",
            "loss : 0.000\n",
            "w : 1.997\n",
            "9.997042655944824\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "lr =0.01\n",
        "for e in tqdm.tqdm(range(50)):\n",
        "  y_pred = forward(x)\n",
        "  l  = loss(y_pred, y)\n",
        "  l.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    w -= lr * w.grad\n",
        "  w.grad.zero_()\n",
        "\n",
        "  if e % 10 == 0:\n",
        "    print(f\"epoch : {e}\")\n",
        "    print(f\"loss : {l.item():.3f}\")\n",
        "    print(f\"w : {w.item():.3f}\")\n",
        "\n",
        "print(forward(x = 5).item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBUak5v2gJYp"
      },
      "source": [
        "### TORCH METHOD 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4OUYDA6mJfMm"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "x = torch.tensor([1,2,3, 4],dtype = torch.float32, requires_grad = False)\n",
        "y = torch.tensor([2,4,6,8], dtype = torch.float32, requires_grad = False)\n",
        "w = torch.tensor(0.0,dtype = torch.float32, requires_grad = True)\n",
        "\n",
        "#otra forma seria : instanciar clase que devuelve objeto MSEloss\n",
        "# loss = nn.MSELoss(size_average=None, reduce=None, reduction='mean')\n",
        "\n",
        "def forward(x):\n",
        "  return x * w\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rt8l9pjvPuH4",
        "outputId": "34afe7b2-0c27-406c-dca6-831d92e4aa0b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:00<00:00, 3845.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 0\n",
            "loss : 30.000\n",
            "w : 0.300\n",
            "epoch : 10\n",
            "loss : 1.163\n",
            "w : 1.665\n",
            "epoch : 20\n",
            "loss : 0.045\n",
            "w : 1.934\n",
            "epoch : 30\n",
            "loss : 0.002\n",
            "w : 1.987\n",
            "epoch : 40\n",
            "loss : 0.000\n",
            "w : 1.997\n",
            "9.997042655944824\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "lr =0.01\n",
        "for e in tqdm.tqdm(range(50)):\n",
        "  y_pred = forward(x)\n",
        "  # simula la funcion de loss implementada a mano antes\n",
        "\n",
        "  # Metodo 1: instanciando clase de error\n",
        "  # l = loss(input = y_pred, target = y)\n",
        "\n",
        "  # Metodo 2 : simulan la funcion de loss implementada a mano antes mediante una funcion de error built in de torch:\n",
        "  l  = nn.functional.mse_loss(input = y_pred, target = y, size_average=None, reduce=None, reduction='mean')\n",
        "  l.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    w -= lr * w.grad\n",
        "  w.grad.zero_()\n",
        "\n",
        "  if e % 10 == 0:\n",
        "    print(f\"epoch : {e}\")\n",
        "    print(f\"loss : {l.item():.3f}\")\n",
        "    print(f\"w : {w.item():.3f}\")\n",
        "\n",
        "print(forward(x = 5).item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEYAJ4W9hr5X"
      },
      "source": [
        "### TORCH METHOD 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3yaq1ZBRQIqq"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "x = torch.tensor([1,2,3, 4],dtype = torch.float32, requires_grad = False)\n",
        "y = torch.tensor([2,4,6,8], dtype = torch.float32, requires_grad = False)\n",
        "w = torch.tensor(0.0,dtype = torch.float32, requires_grad = True)\n",
        "\n",
        "# loss class\n",
        "loss = nn.MSELoss(size_average=None, reduce=None, reduction='mean')\n",
        "\n",
        "# crea optimizer para prescendir d actualizacion de pesos a mano\n",
        "optimizer = torch.optim.SGD(params = [w], lr=0.01)\n",
        "\n",
        "def forward(x):\n",
        "  return x * w\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZfjHjk2iBTU",
        "outputId": "f645192e-1657-4664-ec98-d50fedc36007"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:00<00:00, 543.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 0\n",
            "loss : 30.000\n",
            "w : 0.300\n",
            "epoch : 10\n",
            "loss : 1.163\n",
            "w : 1.665\n",
            "epoch : 20\n",
            "loss : 0.045\n",
            "w : 1.934\n",
            "epoch : 30\n",
            "loss : 0.002\n",
            "w : 1.987\n",
            "epoch : 40\n",
            "loss : 0.000\n",
            "w : 1.997\n",
            "9.997042655944824\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in tqdm.tqdm(range(50)):\n",
        "  # forward\n",
        "  y_pred = forward(x)\n",
        "\n",
        "  # compute loss for all the batch\n",
        "  l   = loss(input = y_pred, target = y)\n",
        "\n",
        "  # compute the gradients for each w_i : dloss/dw_i (usa grafo computacional y almacena ,en el tensor .grad asociado a cada parametro, el valor del gradiente que luego usa el algoritmo de optimizacion)\n",
        "  l.backward()\n",
        "\n",
        "  # paso del optimizer (en este caso un simple SGD) equivale a lo que haciamos a mano de w += -lr*w.grad\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"epoch : {epoch}\")\n",
        "    print(f\"loss : {l.item():.3f}\")\n",
        "    print(f\"w : {w.item():.3f}\")\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "print(forward(x = 5).item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eft4lJyOqM9q"
      },
      "source": [
        "### TORCH METHOD 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "BYPG397vqPYO"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "x = torch.tensor([[1],[2],[3], [4]],dtype = torch.float32, requires_grad = False)\n",
        "y = torch.tensor([[2],[4],[6],[8]], dtype = torch.float32, requires_grad = False)\n",
        "\n",
        "# Dimension layers (in and out, entra 4 samples (batch) sale 1 output por cada input) teniendo en cuenta el batch: X_input(1,4) * W(4,1)--> (1,1) // sin batch : X_input(1) * W(1)--> (1)\n",
        "batch_size , features  = x.shape\n",
        "# features == dim_input y en este caso features ==  dim_output pq capa solo 1 parametro (como que solo una neurona)\n",
        "\n",
        "# model [capa lineal inicializa un tensor paramters asociado a la capa en funcion de las input y output dimesnions especificadas ]: capa lineal con 1 W y 1 X input (escalares) ; luego dim_input = 1 y dim_output = 1\n",
        "model = nn.Linear(in_features= 1, out_features = 1)\n",
        "\n",
        "# loss class\n",
        "loss = nn.MSELoss(size_average=None, reduce=None, reduction='mean')\n",
        "\n",
        "# crea optimizer para prescendir de actualizacion de pesos a mano\n",
        "optimizer = torch.optim.SGD(params = model.parameters(), lr=0.01)\n",
        "\n",
        "def forward(x):\n",
        "  return x * w\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrJjVppMsOQC",
        "outputId": "34a42a02-75f1-4df4-9e3b-794be874aec0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 0\n",
            "loss : 21.203\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'Linear' object has no attribute 'get_parameters'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[65], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ml\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parameters\u001b[49m()\u001b[38;5;241m.\u001b[39mitems()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m   optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(forward(x \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m)\u001b[38;5;241m.\u001b[39mitem())\n",
            "File \u001b[1;32mc:\\Users\\Jorge\\Desktop\\MASTER_IA\\TORCH\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1709\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1709\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'Linear' object has no attribute 'get_parameters'"
          ]
        }
      ],
      "source": [
        "for epoch in tqdm.tqdm(range(50)):\n",
        "  # forward now is == to calling the model\n",
        "  y_pred = model(x)\n",
        "\n",
        "  # compute loss for all the batch\n",
        "  l   = loss(input = y_pred, target = y)\n",
        "\n",
        "  # compute the gradients for each w_i : dloss/dw_i (usa grafo computacional y almacena ,en el tensor .grad asociado a cada parametro, el valor del gradiente que luego usa el algoritmo de optimizacion)\n",
        "  l.backward()\n",
        "\n",
        "  # paso del optimizer (en este caso un simple SGD) equivale a lo que haciamos a mano de w += -lr*w.grad\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"epoch : {epoch}\")\n",
        "    print(f\"loss : {l.item():.3f}\")\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "print(forward(x = 5).item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNpS7kFUkohP"
      },
      "source": [
        "### TORCH METHOD 5  : custom module + dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "znZayzMfktvh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(100, 1) (100,)\n",
            "(100, 1) (100,)\n",
            "torch.Size([100, 1]) torch.Size([100])\n",
            "torch.Size([100, 1]) torch.Size([100, 1])\n",
            "Media de target y : -0.000\n",
            "Media de target y std: -0.000\n",
            "\n",
            "\n",
            "\n",
            "Module : LinearRegression(\n",
            "  (linear): Linear(in_features=1, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "Module : Linear(in_features=1, out_features=1, bias=True)\n",
            "\n",
            "Parameter : ('linear.weight', Parameter containing:\n",
            "tensor([[0.9165]], requires_grad=True))\n",
            "\n",
            "Parameter : ('linear.bias', Parameter containing:\n",
            "tensor([-0.5463], requires_grad=True))\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# data samples\n",
        "x_numpy , y_numpy = datasets.make_regression(n_samples =100, n_features= 1, noise =20, random_state = 1)\n",
        "x_numpy_std  = (x_numpy - np.mean(x_numpy)) / np.std(x_numpy)\n",
        "y_numpy_std = (y_numpy - np.mean(y_numpy)) / np.std(y_numpy)\n",
        "print(x_numpy.shape, y_numpy.shape)\n",
        "print(x_numpy_std.shape, y_numpy_std.shape)\n",
        "\n",
        "# to torch tensor\n",
        "x = torch.from_numpy(x_numpy_std.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy_std.astype(np.float32))\n",
        "print(x.shape, y.shape)\n",
        "# reshape y from (100) tensor -> (100,1) tensor\n",
        "y = y.view(y.shape[0],1)\n",
        "print(x.shape, y.shape)\n",
        "print(f\"Media de target y : {y.mean(dim = 0).item():.3f}\")\n",
        "print(f\"Media de target y std: {y.mean(dim = 0).item():.3f}\")\n",
        "\n",
        "# numbeer of samples and number of features\n",
        "# x (100,1)\n",
        "n_samples = x.shape[0]\n",
        "features = x.shape[1]\n",
        "\n",
        "# custom class model (linear regression layer)\n",
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self, input_size, output_size) -> None:\n",
        "       super().__init__()\n",
        "       self.in_size = input_size\n",
        "       self.out_size = output_size\n",
        "       # model [capa lineal inicializa un tensor paramters asociado a la capa en funcion de las input y output dimesnions especificadas ]: capa lineal con 1 W y 1 X input (escalares) ; luego dim_input = 1 y dim_output = 1\n",
        "       self.linear = nn.Linear(in_features= self.in_size, out_features = self.out_size, bias = True)\n",
        "    def forward(self,x):\n",
        "        return self.linear(x)\n",
        "    \n",
        "\n",
        "# instanciar capa y crear modelo\n",
        "model = LinearRegression(input_size = features, output_size = features)\n",
        "# loss class\n",
        "loss = nn.MSELoss(reduction='mean')\n",
        "# crea optimizer para prescendir de actualizacion de pesos a mano\n",
        "optimizer = torch.optim.SGD(params = model.parameters(), lr=0.01)\n",
        "\n",
        "# MODULE CLASS DOCU:\n",
        "\"\"\"nn.Module :\n",
        "Base class for all neural network modules.\n",
        "\n",
        "Your models should also subclass this class.\n",
        "\n",
        "Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes: \n",
        "self.sub_module = nn.Linear(...)\"\"\"\n",
        "\n",
        "# Iterate along all de modules inside a network class or model class. Notice that LinearRegression module has inside a linear layer \"module\" or only linear layer\n",
        "# note that the atribute name : self.linear will define the string \"linear\" to refer to that layer inside a module\n",
        "# this will be useful when ,inside a class module, there are several layers\n",
        "print(\"\\n\")\n",
        "\n",
        "for m in model.modules():\n",
        "    print(f\"\\nModule : {m}\")\n",
        "\n",
        "# iterate along all the parameters inside a module ( a module can have a lot of layers with their parameters)\n",
        "for p in model.named_parameters(prefix='', recurse=True, remove_duplicate=True):\n",
        "    print(f\"\\nParameter : {p}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APdfIuxGQTuu",
        "outputId": "8d679be4-54fe-499b-86be-548f69d2049f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:00<00:00, 1515.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 0\n",
            "loss : 0.360\n",
            "w : 0.918\n",
            "Predictions :tensor([[4.5543],\n",
            "        [5.5050]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAGdCAYAAAAvwBgXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA560lEQVR4nO3df5QU5Z3v8U/RyiAJMwoMCPbgiMlmNzdZkrCKEieZiWyie5LAdkCP3OSoa3Q3ohHJLzA/kJMQNmoCrD8STbKae1wQV0bda+7mrpIZJIm/vexGE9xgIIwD6MCEGUUySE/dP2p66O6q6q7qruqq7n6/zpkzTk119yPJsT48z/f5PoZpmqYAAAAiMCbqAQAAgPpFEAEAAJEhiAAAgMgQRAAAQGQIIgAAIDIEEQAAEBmCCAAAiAxBBAAAROaEqAdQyPDwsPbu3asJEybIMIyohwMAADwwTVOvv/66pk+frjFjCs95xDqI7N27Vy0tLVEPAwAAlKCnp0fJZLLgPbEOIhMmTJBk/Ys0NjZGPBoAAODF4OCgWlpaRp/jhcQ6iGSWYxobGwkiAABUGS9lFRSrAgCAyBBEAABAZAgiAAAgMgQRAAAQGYIIAACIDEEEAABEhiACAAAiQxABAACRiXVDMwAAYiedlrZtk/btk6ZNk9rapEQi6lFVLYIIAABedXZK110nvfLK8WvJpLR+vZRKRTeuKsbSDAAAXnR2SgsX5oYQSertta53dkYzrlKl01J3t7Rxo/U9nY5kGAQRAACKSaetmRDTtP8uc23p0sge5r51dkqtrVJHh7R4sfW9tTWSMEUQAQCgmG3b7DMh2UxT6umx7ou7mM3sEEQAAChm375g74tKDGd2CCIAABQzbVqw90UlhjM7BBEAAIppa7N2xxiG8+8NQ2ppse6LsxjO7BBEAAAoJpGwtuhK9jCS+Xnduvj3E4nhzA5BBAAAL1Ip6YEHpNNOy72eTFrXq6GPSAxndmhoBgCAV6mUNH9+9XZWzczsLFxohY7sotWIZnYIIgAA+JFISO3tUY+idJmZHacOsevWVXxmhyACAEC9idHMDkEEAIB6FJOZHYIIAAC1popOCCaIAABQS6rshGC27wIAUCtido6MFwQRAABqgc9zZNJp6Ze/lN58s3JDdEIQAQCgFvg4R+b556UTTpDOO8/KJlEiiAAAUAs8ng9zxaoWzZ59/Oe5c0Maj0ehBpE1a9borLPO0oQJEzRlyhQtWLBAL730UpgfCQBAfSpyPkyfJsuQqX/uPnP02ubN0mWXhTyuIkINIlu3btWSJUv05JNP6tFHH9Vbb72lj370ozp8+HCYHwsAQP0pcI7MXbpSU9SXc21wMB6baAzTdKpqCUdfX5+mTJmirVu36kMf+lDR+wcHB9XU1KSBgQE1NjZWYIQAAFSxzK4ZSTJNvaUTNEWv6ZBOGb3lhhuk1avDHYaf53dF+4gMDAxIkiZOnOj4+6GhIQ0NDY3+PDg4WJFxAQBQE7LOkfn3V96jv9G/5/z6v/9beuc7Ixqbi4rNiAwPD+uTn/ykDh06pF/84heO99x4441atWqV7TozIgAAeJe/OnPeB009vs1wWrUJhZ8ZkYrtmlmyZIleeOEF3Xfffa73rFixQgMDA6NfPT09lRoeAABV76mn7CHkkUekbb+oXAjxqyJLM9dcc40eeeQRPf7440omk673NTQ0qKGhoRJDAgCgpkyfbt/B298vnXKK8/1xEWoQMU1T1157rR588EF1d3frjDPOCPPjAAAIht9D4yI8ZG5gQDr55NxrEydKBw9W5OPLFurSzJIlS3Tvvfdqw4YNmjBhgvbv36/9+/fryJEjYX4sAACl6+yUWluljg5p8WLre2ur+zktfu8P0Fe+Yg8hv/hF9YQQKeRiVcNlQeruu+/WZR46qLB9FwBQUZntr/mPxszz7IEHcptv+L0/IKYpjXGYSqhcQ47CYlOsapqm45eXEAIAQEX5PDTO9/0BeewxewhZvTo+IcSvivYRAQAgtnwcGqf2dv/3B8BpoeGNN6S3vS2Qt48Eh94BACB5PjRu9D6/95fh1VftIeQ977GyTjWHEIkgAgCoJ+m01N0tbdxofc9eNilyaJztPr/3l+jv/k469dTca//1X9Kvf13W28YGSzMAgPrQ2WnVdGQvpyST0vr1VkFp5tC43l7nggvDsH7f1mb97Pd+n4aHnXcAV2stiBtmRAAAtS+zuyW/pqO317re2Wk99devt67nr4Nkfl637ng68Hu/D5s321/2/e/XXgiRCCIAgFrnZ3dL5tC4007LvS+ZdN6K6/d+Dwzj+AG6GUND0j/8g++3qgoVO/SuFPQRAQCUrbvbajJWTFfX8d0tEXRW3b1bym9A/td/Lf3Hf/h6m1jw8/ymRgQAUNtK2d2SSPjbcuv3/jwf/7j005/mXtu5UzrzzJLfsmoQRAAAta1Cu1tK8dZb0tix9uvxXasIHjUiAIDaltnd4nLsiAxDamkpeXdLqX70I3sIue+++gohEjMiAIBal9ndsnChFTqyn/Rl7m4plVMmOnasokOIDWZEAAC1L4TdLaV48UV7CPn0p61sVI8hRGJGBABQL1Ipaf780na3BLArZvZs6fnnc6/t3RtJaUqsEEQAAPWjlN0txTqyFvHmm87nwdRbLYgblmYAAHDjpSNrATfdZA8hP/sZISQbDc0AAHCSTkutrfYQkpE5S2bXLsdlGqeC1OFh9807tcTP85sZEQAAnGzb5h5CJGtao6fHui/LU0/Zw8b111u310MI8YsaEQAAnJTQkXX6dPvL+vulU04JcFw1hhkRAACc+OjI+uqr1mxHdgiZNMmaBSGEFEYQAQDAiceOrB9Y9mGdemrur375S+nAgfCHWAtYmgEAwEmRjqymKY3p2SP15L4svltA4okZEQCoR+m01N0tbdxofU+nox5RPLl0ZL2jaYXGaDjn2oUXEkJKwYwIANSbMht01Z28jqzG4kukQ7m3/PGP0sknRzG46seMCADUkzIbdNWtREL/NbHdCiF5TJMQUg6CCADUi3TamglxWj/IXFu6lGUaB4YhzZqVe23DBpZigsDSDADUCz8Nuvyex1Kj3npLGjvWfp0AEhyCCADUqvwTY3t7vb3OayOvGtfS4pzbCCHBIogAQC1yKkidPNnbayt9Ln1+YGprczy7pZKcWocMDEgcexY8akQAoNa4FaQW67A10qBLbW3hjS1fZ6d1sFxHh7R4sfW9tTWyotl77nEOIaZJCAkLQQQAakmhgtRs+U/bzM/r1lVuNiJmO3gMQ7r88txrd97JUkzYCCIAUEuKFaRm5C/TJJNW465K9RGJ0Q6egQH3WZCrrgr94+seNSIAUEu8FpquXWt1C42qLiMmO3jcjpFhFqRyCCIAUEu8Fpqedlq0W3S9BqYQd/A4hZA//UlqaAjtI+GApRkAqCUeT4ytaEGqE6+BKYQdPDfe6L4UQwipPIIIANSSzImxUjwKUt1EFJgMQ1q1Kvfa//k/LMVEiSACALXG5cTYihekFlLhwLRrl/ssyIUXBvIRKJFhmvHNgYODg2pqatLAwIAa2cANAP7EsFGYjVPjtZYWK4SUE5iy/t2dDqobN046cqT0t0dhfp7fBBEAQLSCDkxZ4caQ/RGXTktjWA8IlZ/nN7tmAADRSiSC28Ez0iSt3fy5tsr+nubmTmlMDJamMIpMCACoDSNN0gxz2BZCfqEPyjTGVKxJGrxjRgQAqlk11IFUyNN3bdecV3ps100ZmX+oSJM0+EMQAYBq5VTomUxau1Gi3BkTQTiydsTMzrl2jp7QE5prvznEJmnwjyACANUoc2Bc/n6DzIFxUW3TdQpHkydLd9whLVoU+MeZpnPh6egsiJMQmqShdNSIAEC1idGBcTncTtM9cEC66CLpy18O9ONOOcUlhBguj7a4dJVFDoIIAFQbPwfGVUqhcJRx883WTE0ADEM6dCj32u9+N7IrJnND/gukeHSVRQ6CCABUmxgcGGdTLBxlXH21tGWLtHGj1N3te9ams9O9Q+o73qHq6CqLHNSIAEC1ifDAOFdeQ09fnzRv3vGffRTXOgWQz35W+uEP8y6mUtL8+ewmqhIEEQCoNpkD43p7nZdCDMP6fSVrIUoNPR6Ka4eGrJbs+Qr2BQ+ySRpCxdIMAFSbOJ6w29Zm7Y7xq0hxrWGUEEJQVQgiAFCN4lYLkUhYW3RL4VJc67QUc+AAIaTWEEQAoFqlUtLu3VJXl7Rhg/V9167oCjIXLZK+9KXSXz9SZ7JunXtB6qRJpb894okaEQCoZnGrhbjpJunss63dMX19/l47bZpjAPnOdwJvQYIYMUwzvpNcfo4RBgDESHab9ylTpEsvlfbudS2u7Z/2PzRp769tv4rvEwqF+Hl+MyMCAAhe/kzNP/2TtTvGMHLThWHIMIelvfa3IITUB2pEAADhcymuNcxh261HjhBC6kmoQeTxxx/XJz7xCU2fPl2GYeihhx4K8+MAAHGWVVy76Ow/yJA9bZim83Zd1K5Qg8jhw4c1a9Ys3X777WF+DACgWiQSMjra9cDTM3Iu//M/MwtSr0KtEbnwwgt14YUXhvkRAIAq8cIL0nvfa79OAKlvFKsCAIKVvWNm5JwX4wTnLq+EEMQqiAwNDWloaGj058HBwQhHAwAhcnhY18ShbJ2d0nXX5ZzE61QLkk5LY9guAcVs18yaNWvU1NQ0+tXS0hL1kAAgeJ2dUmur1NEhLV5sfW9tta5Xs85Oa4vuSAgZpyOuBamEEGTE6v8KK1as0MDAwOhXT09P1EMCgGDlPaxHZU6hrdYwkk5bMyEjay2GTA0pd/vLTydfKvOY/WA71LdYBZGGhgY1NjbmfAFAzch7WOcocgpt7G3bJr3yiu7V/3SeBZGhvznwv2wH2wGh1oi88cYb2rlz5+jPu3bt0vbt2zVx4kTNmDGjwCsBoAaNPKxdZZ9CG8b5MWHWpezb5xhAJCuEZN8HZAs1iDz77LPq6OgY/XnZsmWSpEsvvVT33HNPmB8NAPHj9SEcxsPaoYhUkydLd9xhnZpbhuFhKbH4Etv1nACSMW1aWZ+F2hNqEGlvb1eMz9QDgMry+hAO+mGdqUvJ/+/xgQPSRRdJX/qSdWpuCZxOy5VcQsikSdYsDJAlVjUiAFDT2tqkZNL96W0YUktLsA/rQnUpGTffbJ0D45PTv8Y2neccQgAXBBEAqJREQlq/3vrn/Kd45ud164LtJ1KsLiXj6qs9F8l+8YvOIcSUofP0S/cXHjxIsSpsCCIAUEkup9AqmbSup1LBfp7XepO+Pk8hwTCk737Xft3csDHY8aBuxKqzKgDUhVRKmj8/3M6qmR0yv/mN99ds3mx9dxjL4cPS299uf8noik93RPUvqHqGGeNq0sHBQTU1NWlgYICeIgDql99tt047ZPxIJq0lpJHZGdeC1OynRzptdYft7XWuRzEM63137aqNVvYoyM/zm6UZAIgzv+3g3Tq3+pHV5dUphOza5ZA1oqh/QU0giABAXPltB+9lh4wXpqkPm10yPmWvVzFNKwc5qnT9C2oCSzMAEEeZpQ63mQ2npY7ubmvGpExOHVLnzJGefNLjG9TqycLwzM/zm2JVAIijUtrBl7kjZY9adLr2OH6UL4lEOC3qUZNYmgGAOCqlHXwZO1IMmc4hpKu75PcEvCCIAEAcldIOvljnVhdOSzGDapTZMoOW7AgdQQQA4qiUdvCFdq44vYVMxxBiGmM0wXiDXS6oCIIIAMRRqdth3Xau5HEKIEu11jonhl0uqCCCCADEVaHtsJs2SRMnShs3Wrtlss+JSaWk3bulxx6z7smyRR9xngXp6tbaDadKXV3WThxCCCqE7bsAEHf522EPHJCuvz53V01eN9RRmV4kkgxz2PHt4/sUQLWisyoA1JLMdthLLpH6+6WLLvLe5GxkVsUphKT/tZMQgsgxIwIAUfPaAKyEJmeu58QcS1OIitAwIwIA1cLPWTJ+mpzJOYR861sjSzGEEMQEnVUBxFccW4UHOaZM/Ub+xHRmmSV/54rHJmffvH2ivuHQ6T2+89+oZwQRAPHkdJS9W0FmNY6p0AF1pmlNZyxdKs2ffzzoeGhyZsiUHnB+SyCOWJoBED9+T52txjH5XGaRVLDJ2bAM5225JiEE8UYQARAvxWYKJGumILtvRjWOqZSzZFyanBkylZB9VwwBBNWAIAIgXkqZKajGMZVyloxka3LmNAvy0EOEEFQPggiAePEzU5BOW11FnbqLRjUmr0o5SyYjldK5p+1xXYqZP9/7MICoUawKIF68zhT87nf2nhphFbOWOntRzJVXSitX2q8XOktm9Nf2AMMsCKoRDc0AxEumaVdvr/OT1TCs81MOHnT+nRT8gW1expTXSKwgp9032VparBCS9+9w6JB0yin22+P7X3HUKxqaAaheXk6ddRNWMWupJ+E6cdt9k7FqleOhc4ZBCEFtIogAiJ9Cp87eeKPzbEhGpnD01luDDSOFxuR1BqbQ7hvJShs/+pHj5Xy//jUhBLWBpRkA8eXUxfT++61W6F6EUTOSGVNvr9TXJzU3W+HES4fV7m6rhXsxXV1Se7v7OTGx/a82YPHz/KZYFUB8ZU6dzeanINStVXo2vy3bEwnrBNzly/0XyvrYfUMIQb1gaQZAdSm27TVbsZoRPwfOZb+m1A6rHkLUi3q3jMWX2K7TIRW1iqUZANUnEwYk70/nkeUO23u47YJxmkXJ7J5xKzQttnumyO4bp74gUkgBJI4HCqJmsGsGQG1zKxwtJHtZpFjRqGlKV11ln0Upt8Nqgd03TiGkvz+kEFLKTBAQEoIIgOqUSkm7d0tr13q7P3tZpFigkKydOatX514LouurQ4t2tw6pTtt1yxbHAwVR1wgiAKpXIiFde63/VuleA8X69VaAyISK3/zG2+syXV+zZxymTbMCiDQaopwCyNlnh1gLEscDBVH3CCIAqlspzca87rzp77dmRTKh4lvfKny/YUiTJllt2/NnHPr6pEWLpC9/WZs2ScYJ9noM05Seesrb0EoSxwMFUffYvgugergVWGaWO/LbpieTjq3S1dZmtYnv7y/+mU5nwTjxsotHknHzTY7XK7JtIIzD+4AyMSMCoDoUK7DM1Ix0dUkbNljfHVqlS7LCy3XXBTs+D11fnZZijh2r4LbcsA7vA8rA9l0A8ee21bacQ+7SaWnq1MLt4r342tek888v2PW1ottyCwn68D7ABdt3AdSOsAosEwnprrvKHp7e/W6rP0ki4TiT4BRCPq/1MjdsLP+z/Qry8D4gIAQRAPFWToGl2xbajFRK2rzZmgUoVXb4aGuzzp6R9Fn90Hlbrgyt19Lolj+COLwPCBDFqgDirdQCy85O5+LV/PNgUikroFx0kb9xZZYxsrcFJxLSHXfIWLTQ8SWmRmYd8rcTV1oqJc2fT2dVxAJBBEC8lVJg6VZT4nQIXjotLVvmb0wuyxjptHSCQwgZDSCZ18Zh+cPpQEEgAizNAIi3Yofc5Tcs81tT4qXLaj6HZQzDkE5w+KtdTghpaWH5A8hDEAEQb34LLP3WlHhd+vna11y3BTtlpH/W5VYImTzZCj6FthMDdYwgAiC+MsWmQ0NWj47p03N/71Rg6bemZMoUb/e3t0uXXHJ8h4ysjOEUQkwZulz3WD8cPGgFqf7+6JdjgBiiRgRAPLkVm65aJb3zne4FlhVq2uW2UpSzFCNZMzCGYc2KzJ9PGAHyMCMCIH4KnRB7441SQ0POzESOtjbrvBc3+TUlr73mbUwj9x044D4LYgsho7/kDBfADUEEQLyU28Ds4YcLd0s1zdyaEh8zKIYx2iYk9y29NifjDBfAhiACIF7KbWB21VWF33/CBGuJJMPjrhyjo932q6efHslGnOEClIwaEQDx4qfYNP803rfeKn52zOuvWwWw559v/ZzZlbNwoRU6smdiDEOGOSz12N8mZ8ImE2aKneESZRMzIKaYEQEQL15nDX73O/tpvF63xv7857k/u7Q9N8xhx5fbsgZnuAAlI4gAiBcvSyWTJkkrV9qXcN54w9tn7Nljv5ZKSbt3S11deu5b/+58ToxZ4MRcznABSsLSDIB4KbJUEogZM1w/2+hod/yVawDJxhkugG/MiACIn0KzCzfeWLwOpJiPfMTxslPO6evzGEIyMme45DU/A+CMGREA8eQ2u3D//eW976RJtsPeXJuT+QkgAEpSkRmR22+/Xa2trRo3bpzmzJmjp59+uhIfC6DaOc0ulLsF9q67cmYpnEJIQwMhBKiU0IPIpk2btGzZMq1cuVLPP/+8Zs2apY997GN6zWs3QwDI5rWY1WlZZ/Pm0aLR225z6ZBqSn/6U8BjBuDKMM1wc/+cOXN01lln6bbbbpMkDQ8Pq6WlRddee62WL19e8LWDg4NqamrSwMCAGhsbwxwmgGqSaQEvORezPvBAwaJRlmKAcPl5foc6I3L06FE999xzmjdv3vEPHDNG8+bN0xNPPGG7f2hoSIODgzlfAGDjZausS9GoUwg5dowQAkQl1GLVAwcOKJ1Oa+rUqTnXp06dqh07dtjuX7NmjVatWhXmkAAEKb+zaSW3qvrcKsssCBBPsdq+u2LFCg0MDIx+9fQ49FUGEA+dnfbOpq2t1vVK8bhV1imELNCDMpMtlR0vAJtQZ0QmT56sRCKhV199Nef6q6++qlNPPdV2f0NDgxoaGsIcEoAgZGo08qcTenut60F2Ei1j1qWjwzpWJp+pkWTSawQ/XgC+hDojMnbsWM2ePVtbtmwZvTY8PKwtW7bo3HPPDfOjAYQlnZauu855TSNzbelS675ylTHrYhhFQkgY43WSTlsD2bjR+h7W5wBVKvSlmWXLlumHP/yhfvKTn+i3v/2tPve5z+nw4cO6/PLLw/5oAGHYts1+xks205R6eqz7ypGZdcn/rMysi0sYOXbMZVuujNwQEvR4ncRh+QqIudA7q1588cXq6+vTN77xDe3fv1/ve9/79LOf/cxWwAqgSuzbF+x9TorNuhiGNYvx8Y9Lv/rV6LKN0dHu+HaOASTI8Tqp5PIVUMVC7yNSDvqIADGQX6ORTktZW/JddXXZWql71t1tzR4U09xsHQYjOZ6W++1vSyvO9fhe5Yw3XzptzXy4zRwZhrXVeNcuzqJBTfLz/OasGQDuOjutmYnsB2oyaXUu7e93nrHIPGTb2kr/XK+zE319jgFEyhpaeqQTa29veOPN52f5KqjwA1SpWG3fBRAjhWo0Dh48vkSSLfPzunXl/U3f43kyriGkZcbxotBEQlq/Pnd8o28Q0HjzVWL5CqgRBBEAdl5qNCZNkqZPz/1ddmfTchQ5T2a/pjqGkNGC1PziUy+dWIPk9WC+cg/wA2oASzNAPfHak8PL0sLBg9Jjj1mvD7qzamYWY+FCK4xkBSLXWZD8gtT82QafnVjL0hbBchBQpZgRAeqFn62kXpcMXnutcGfTcnpoOMxiOIWQbTrPeVdM/mxDJdvRR7EcBFQpgghQD/z25AhiaSGIHhqplLR798iCi/NSzHn6Ze5Fw5BaWnJnG6Lo51Hp5SCgSrF9F6h1pWwlzbzGbWlBsu7duFFatMj+O7ceGpnZAB8PYtfD6oyRv0dlf4bT+wc4lpJEeTAgEBE/z29mRIBaV0on1OylBTfptHTxxfZZhYBawHd1uXRINUfexstsQyXb0bvxeDAfUK8IIkCtK3UraSol3X9/8Qdn/oPca/C59VbXAGAY0kc+4vzSnPHt3m0llg0brO+7duXOblSqHT2AkhFEgFpXTr3H5MmFZwucHuReg8/11zvWaTjNguzb57JCVGy2gX4eQOwRRIBaV6Qnh2NxZ0YpD3I/vTGyimUNw30p5tRTvb9lDvp5ALFHEAFqXTlbSUt5kBcLPtlGpjmMTzkXi5ZdSl9OCANQEQQRoB64bSWdPFnatMl910gpD/JCwSfPat0gwxy2XR8tSC0X/TyA2COIAPUilZLWrrVOrM3o65OWLXPvp1Hqg9wt+GS/XKa+ptW264E3FKCfBxBr9BEB4iiM3hPl9NNwOoW3pcUKIYUe5Om0tTvm+utzP9KhOdmxx7qVOL+9+L9HqejnAVSMn+c3QQSIG6eHfjJpzUyU+rf3UpqaOb1HKQ/yrOZoTssw0shpuYU+G0BVoaEZUK38tmKXvJ3nEkQ/jWJbZd3GMbK84xRC5uqXVodU6jSAusXpu0BcFOsCahhW87D5848/tL3Onvjdhut39qPAOM7+x5SeecY+k2NqpNB1HXUaQD0jiABx4WfWor3dveYjM3uSXfPhZxuu36WhAuNw3Za7YaM0rYs6DQAszQCRyyxpbN7s7f59+/yfoeKlt8fEidY4/CwNpdPS5z9vG8cxJQpvy+XcFQAjCCJAmIrVb2QfT3/bbd7ec9o0/zUfXnp79PdLq1b5OyBu9WorpGQxZOpEHXN9CwDIRhABwpIdMhYvtr5nn63iVpjqJrt5WCmt1z309igoP9x0dkorV+YO0WFb7j/qK9ZSDAA4oEYECEOx+o3777d6a3idJshvHlbqGSqplDQ8LH3uc9KBA97eI9++fdLRo9I//MPx4TkEEGmkIFWy6kGKoc8HUJeYEQGC5qV+4+qrvc+ESPYuoKWeodLZKV10UekhRJJ+9ztrVqWvz/qoYiHEy1kuxWaPANQsgggQNC/1GyMP8aKuuUbq6rKafWXvWCml9XqhgOTVpEnWcsyBA3pNzY4hxJRxPIQ4jSNfKb1TANQMgggQNK/1G1586lPuu0v8nqFSLCB58dZbkqxZkKl6zfbrnAAiWcWvxVrA+9n9A6DmEESAoHmt35g8ufzj6VMpafdua9Zkwwbn2ZOMIALS4KDjLMgTOsceQpJJ6atfLfx+QXR8BVDVKFYFgpap3+jtdf6bfuZcl+9+V7r4Yuvn7Pu8Hk+fX9x50UWF7/cakFwUrQXJudmwlo6KFZuWsvsHQE1hRgQImtf6jUWLSj+evpTiTi9NzVz4CiHNzcXHn1Hq7h8ANYPTd4GwOLVKb2mxQkj2Q7qUc12ctgZnAkahEJB5reSpaPUJnaO5esJ23TGASFYIeeUVaezYou8tKedk3oKzR5zMC1QVP89vgggQpqB7Y2Qe3G51FV4e3IUCkjT6O9dZEGNkItVpOcnrTEj+eJzCUTnvCSBSBBGgGpQSUrq7rWWYYrq6rN02pXx2Oi3jBPs4+vqs+lrPMz1+hPGeACLj5/lNsSoQBb8n3GYEVdyZSDgGFWsSwh5Ccv66kkpJ8+cHO9MTxnsCqAoUqwKVVk4DrxCLO51qWE8+2XQuJUkkrKAwbZoVHLZtK7/XRyYccTIvUFcIIkAlFWvgZZqFG3iV2tq9gNtvd347U4b++PYZzsGIluwAAkIQASrJS3fTQg28SmntXoBhWF3k843uinGapaElO4AAEUSASurt9Xbft79tBYqjR+2/89va3YXTLMgxJXK35ua3WaclO4CAEUSASvJ62N2jj0rXXy+NHy99+cv23/tp7Z7HMNyXYhIadvhFVpt1WrIDCBi7ZoBKam72d386Ld18s/XPN92U+zuXnS+FOAWQi8/5g+57srX4i/20WaclOwCPmBEBKil/OcWr733PeZnGo7/9W5dZEFO6b80ub28ybRot2QEEjiACVFJm14tf6bR0xx0lfaRhSA89ZL8+WubhZydOCLt2ANQ3gghQSZldLyUcPKeXX/Z1+7Fj7rMgObWmfnbiBLxrBwAIIkDY0mmrNfvGjdb3+fOt3S1+Z0bOPNPzrYYhnXii/brrgQ5+duIEtGsHACTOmgHCVaiVe6aleU+PdNll0rDDjpWMREJ6801Pp9o6zYLcead01VUexuvn/JugD/QDUDM4awbIiPJhmWn8lZ/1M42/smcPfv3r47tjnCxbVjSEuK32+Pqrhp+dOCXs2gGAfCzNoHZF2Ybcb+Ovm26SvvQle0gaM0b6+Melv/mbgk3Cygoh+UtHNCMDUEEEEdSmqNuQl9L466abrOWXtWulCy6QGhut5ZpHHnENUX19HgtS3XR2SqefnhvWTj+dNu0AKoYggtoThzbkXht65d83dqw0Y4b0f/+vNDiY+7u8EGUY0pQp9rf0vBTT2Sl96lP2tvO9vdZ1wgiACiCIoPaE2Ybc6zJGqY2/PIYop1mQZ5/1EULS6eLVq1ddxTINgNARRFB7Sp2NKMZPzYmXxl/JpPWgzw41RUKUYQ7L6Nlju26a0uzZPv5durulgwcL33PwoHUfAISIIILaE0Ybcr81J8Uaf5mmdOSING9ebqh5+GHXIRhynu4oaQO+14BBEAEQMoIIak/Qbcgzyxh+a07cGn9NnGh9z5+R6O21upLmeVazHUOI54JUAIgxgghqT9BtyFevLryMUajmJJWSdu+WurqkDRukxx6Txo1zfx/DyBmXIVNn6Vn7rcfKrN3w2v+DPiEAQkYQQW0Kqg15On081BTjVHOS31BNsu9SyWaaozMrTrMgBzVJ5ubO8puytbdLkyYVvmfSJIIIgNDRWRW1K5U63ka91M6q27ZJ/f3e7s2vOXFq755ZlinAtRakZYa07ofBnOWSSEh33WVt03Vz1120bAcQutBmRFavXq25c+dq/PjxOvnkk8P6GKCwTBvySy6xvvt9sHrdWTNpUm7NiVtxa5FQ4xRCTpv4psyubmnXrmAPlEulpM2b7YfvJZPWdQ6vA1ABoc2IHD16VIsWLdK5556rH//4x2F9DBAurztrPv/54yGnUC8QF/fqf+ozutd23XqL8ZLaPb+XL0HMGgFAGUILIqtWrZIk3XPPPWF9BBC+zA6c3l73YDFpkvTVrx7/uVhDtTwFl2LSu8IPBRxeByBCsSpWHRoa0uDgYM4XEKlCO3AyPvMZK3xktu/6aJTmFELSGiNTRundXwGgisQqiKxZs0ZNTU2jXy0tLVEPCfUqu5X7xInSpk32HTiZmYp163K7rHpYzjFkOvcGkaEx2df9dn8FgCrjK4gsX75chmEU/NqxY0fJg1mxYoUGBgZGv3p6ekp+L6BkTq3cly2zTsXt6rKal0n2BmaZLqsHDhRsqOYUQL6om61ZkHx+ur8CQBXyVSPyhS98QZdddlnBe2bOnFnyYBoaGtTQ0FDy64GyZXa75NeD9PZKF10k3X+/1YfESaYh2bJl0ve+J1188fF27pK+pa/q6/qW/WVOASRzFo3X7q8AUKV8BZHm5mY1NzeHNRYgWsVOvjUM6eqrpb4+9/fIdFltbrYCy0gfEdeCVGOMJCP3M0vp/goAVSq0GpE9e/Zo+/bt2rNnj9LptLZv367t27frjTfeCOsjUa+y6zkyp9iWothuF9MsHEKy7dsnpVJKv7y78DkxQXR/BYAqFtr23W984xv6yU9+Mvrz+9//fklSV1eX2tkqiKA4dS+dPFn69Ket/hh+emIEWRg6bdrIxIb9s3MmXOjjAaDOGaYZ3/M7BwcH1dTUpIGBATU2NkY9HMSNWz1HtmTS2n7rZXahu9sqTC1m8mTrEDynzx2p7TB69th+tWWL9JGPFH97AKh2fp7fsdq+C3jmtXtpZidLZ2fx98w0L3PrF2IYUkuLdMcdx3/O+/115jrHEGKahBAAcEIQQXXy2r00E1SWLi1eO1KoeVl2AemiRY61HYY5rH/S512HAACwI4igOvmp58jsZPHSpTSV8lZAmkpJu3dLXV16/cf3Fy5IBQC4Cq1YFQhVKY2+vIYXrwWkiYSMjnbHtyCAAIA3BBFUJy+H0eXzE148HATnVEryhz9IM2Z4/xgAqHcszaA6ZddzFJMpMg2oS+nZZzuHENMkhACAXwQRVK9MPUcy6X5PwF1KDUN65pncax/+MEsxAFAqggiqW1bRqJYutVqrZ5s4UbrxRqvmowy9ve6zIN3dZb01ANQ1ggiqX6aeY+1aq7h01SorgEhW47GVK63TdL30EnGQOX8uH7MgAFA+gghqy8MPWzMg/f251/00NsviNAvy5puEEAAICkEEtaPY6bmSt8ZmkubMcV+KOemk8oYJADiOIILa4eX0XA+NzQxDevrp3Gu33MIsCACEgT4iqB1eG5a53Pef/ym973326wQQAAgPQQS1w2vDMof73M65I4QAQLhYmkHt8Hp6bl5jM6fbh4cJIQBQCQQR1I5EQrrkksIJIquxmWG4F6S6ZRkAQLAIIqgdnZ1WVambL35x9PRcp6DxH//BLAgAVBpBBLWh0NbdjPvu0yMPp11nQf76r8MbHgDAGcWqCFc6bW2X3bfPKhJtawvkzBebYlt3JRk9e6QFudfGj5cOHw5+OAAAbwgiCE9npzVLkR0Qkknr1NyRJZLAFNi6OyxDCQ3brrMMAwDRY2kG4ejstFqq589SlNhqvSiXrbuGTEIIAMQYQQTBC7DVumcOW3cN2T//hf9ME0IAIEYIIgheQK3WfUkkrCUfSf+uCx1DiLm5U//jL0OoTwEAlIwaEQSvzFbrJUulZJj2ZZhFJz2i++89GnxdCgCgbAQRBK+MVuulGhqSxo2zXze7uqW2C8PZqQMAKBtLMwheia3WS/UXf+ESQkxJ7e2EEACIMYIIgpdVr2ELI5mfs1qtl8MwpB07cq8dOsSuGACoFgQRhCOVkh54QDrttNzryaR1vcx6jX/9V/dzYpqaynprAEAFUSOC8KRS0vz5gXdWdQogDz4oLVhQ1tsCACJAEEG4EgmrTiMAg4POsx0swwBA9WJpBlXBMOwhZNYsQggAVDtmRBB7TksxR49KJ55Y+bEAAILFjAhia90694JUQggA1AZmRBBLTgHkV7+Szj238mMBAISHIILgpNNl75DZu9e+41eiFgQAahVLMwhGZ6fU2ip1dEiLF1vfW1ut6x4Zhj2EXHQRIQQAahkzIihfZ6e0cKE9MfT2Wtc9NDBzWooZHnbvEg8AqA3MiKA86bR03XXO0xaZa0uXWvc5uP5694JUQggA1D5mRFCebdukV15x/71pSj091n15jc2cgsZLL0l/9mfBDhEAEF/MiKA8+/b5vu/FF91nQQghAFBfCCIoz7Rpvu4zDOk978n91Ve+QkEqANQrlmZQnrY260Td3l7nNGEYUjIp87w2jXGZBQEA1C9mRFCeREJav9765/z1lpGfPzn1KY050d5PhBACACCIoHyplLVFN78JSDIpwxzW/342d/lm3z5CCADAwtIMgpFKSfPnj3ZWff71d2r23/+V7TYCCAAgG0EEwUkkpPZ2xx0xGzZIl1xS+SEBAOKNIILAHDvmfCousyAAADfUiCAQX/+6PYSccw4hBABQGDMiKJvTUszhw9L48ZUfCwCgujAjgpI9+6x7h1RCCADAC2ZEUBKnAPL//p/0vvdVfCgAgCpGEIEvR444z3ZQCwIAKAVLM/Dss5+1h5BvfpMQAgAoHTMi8MRpKebYMat1CAAApWJGBAU99pg9hEyaZM2CEEIAAOViRgSunGZBXn5Zmjmz8mMBANSm0GZEdu/erSuuuEJnnHGGTjrpJJ155plauXKljh49GtZHIiB//KP7tlxCCAAgSKEFkR07dmh4eFh33nmnXnzxRa1du1Y/+MEPdMMNN4T1kQjAhRdKEyfmXrvzTgpSAQDhMEyzco+Ym2++Wd///vf1+9//3tP9g4ODampq0sDAgBobG0MeHZxmQYaHna8DAODGz/O7osWqAwMDmpj/1+0sQ0NDGhwczPlC+DZtsoeN97/fmgUhhAAAwlSxYtWdO3fq1ltv1S233OJ6z5o1a7Rq1apKDQlyDhr790tTp1Z+LACA+uN7RmT58uUyDKPg144dO3Je09vbqwsuuECLFi3SlVde6freK1as0MDAwOhXT0+P/38jeLJ3r3tBKiEEAFApvmtE+vr6dPDgwYL3zJw5U2PHjpUk7d27V+3t7TrnnHN0zz33aMwY79mHGpFwvPvd0m9/m3tt82YplYpmPACA2uLn+e17aaa5uVnNzc2e7u3t7VVHR4dmz56tu+++21cIQfBMU3L6n4AdMQCAqISWDHp7e9Xe3q4ZM2bolltuUV9fn/bv36/9+/eH9ZEo4Lbb7CFkwQJCCAAgWqEVqz766KPauXOndu7cqWQymfO7Cu4YhpxrQQYGJFa7AABRC21G5LLLLpNpmo5fqIz//m/3glRCCAAgDijaqFHjx0vvelfute5ulmIAAPHCoXc15tgx6cQT7dcJIACAOGJGpIZ8/ev2EHL11YQQAEB8MSNSI5xqQf70J6mhofJjAQDAK2ZEqtwzz7gXpBJCAABxx4xIFXMKINu3S7NmVXwoAACUhCBShY4csXbF5KMWBABQbViaqTJXXGEPId/8JiEEAFCdmBGpIk5LMceOSYlE5ccCAEAQmBGpAo89Zg8hkydbsyCEEABANWNGJOacZkFeflmaObPyYwEAIGgEkZj64x+liRPt16kFAQDUEpZmYuiCC+wh5K67CCEAgNrDjEjMOC3FDA87XwcAoNoxIxITmzbZw8YHPmDNghBCAAC1ihmRGHAKGvv3S1OnVn4sAABUEjMiEertdT8nhhACAKgHBJGIvPvdUjKZe62zk4JUAEB9YWmmwkxTGuMQ/wggAIB6xIxIBd12mz2ELFhACAEA1C9mRCrEqRZkYEBqbKz8WAAAiAtmREK2d697QSohBABQ7wgiIfr0p6XTTsu91t3NUgwAABkszYRg+K20EmPtx+ISQAAAyMWMSMBeWPeYLYT8+JQvytzcGdGIAACIL4JIgK658GW99/p5OdeO6kT93aHvSQsXWo1CAADAKIJIAPr7rYLU23925ui1f9FimTJ0oo4dX5NZulRKp6MZJAAAMUQQKdNPfiJNmpR77Y86WYu1MfeiaUo9PdK2bZUbHAAAMUcQKVE6bbVov+yy49eu1/dkytDJGnB/4b59oY8NAIBqQRApwTPPSCecYB1al/Gbe57W9/SF4i+eNi28gQEAUGUIIj595jPS2Wcf//kDH5CGh6W/+PRsa4rEqXuZZF1vaZHa2iozUAAAqgBBxKP9+60sce+9x6899JD03HMj2SORkNavt36RH0YyP69bZ90HAAAkEUQ8ueMO+4rKG29I8+fn3ZhKSQ88YG+nmkxa11OpUMcJAEC1qc/Oqum0tXtl3z4rYbS1Oc5UHD0qnXKK9Oabx6+tXCndeGOB906lrITi4f0BAKh39RdEOjul666TXnnl+LVk0lpWyZqxePxx6cMfzn3pyy9LM2d6+IxEQmpvD2S4AADUsvpamunstDqcZocQydr+ktX59OMfzw0h559vFaR6CiEAAMCz+gki6bQ1E+J08tzItT3X3CTDkH760+O/evRR6bHH3DfDAACA0tVPENm2zT4TkuU75pd0+r4nR382DOnIEWnePNeXAACAMtVPjYhLR9MjGqfxOpJz7bvflZYtq8SgAACob/UTRBw6mv5MH9OF+lnOtVfu/5VOWzQ32M/2uEsHAIB6Uz9LM21tOZ1P5+nRnBCS0maZLTN0WmpOsJ/b2Sm1tkodHdLixdb31tbRwlgAAOpZ/QSRrM6nL+ld2qLjxR+/1Ae12VgUfOdTj7t0AACoV/UTRKTRzqfJ6cO6Qj/Sh7RVR3Wi5rb0BN/51MMuHS1dat0HAECdMkzT6UkZD4ODg2pqatLAwIAaGxuDe+NK1Gx0d1vLMMV0ddH8DABQU/w8v+unWDVbJTqfuuzSKfk+AABqUH0tzVSSwy6dsu4DAKAGEUTCkrdLx8YwpJYW6z4AAOoUQSQsWbt0bGEk83PQu3QAAKgyBJEwjezS0Wmn5V5PJoPfpQMAQBWqz2LVSkqlpPnz6awKAIADgkglVGKXDgAAVYilGQAAEBmCCAAAiAxBBAAARIYgAgAAIhNqEPnkJz+pGTNmaNy4cZo2bZo+85nPaO/evWF+JAAAqCKhBpGOjg7df//9eumll7R582a9/PLLWrhwYZgfCQAAqkhFT9/9t3/7Ny1YsEBDQ0M68cQTi94f2um7AAAgNLE8fbe/v1//8i//orlz57qGkKGhIQ0NDY3+PDg4WKnhAQCACIRerPqVr3xFb3vb2zRp0iTt2bNHDz/8sOu9a9asUVNT0+hXS0tL2MMDAAAR8r00s3z5cn3nO98peM9vf/tb/fmf/7kk6cCBA+rv79cf/vAHrVq1Sk1NTXrkkUdkOJxKmz8jMjAwoBkzZqinp4elGQAAqsTg4KBaWlp06NAhNTU1FbzXdxDp6+vTwYMHC94zc+ZMjR071nb9lVdeUUtLi371q1/p3HPPLfpZmfsBAED16enpUTKZLHiP7xqR5uZmNTc3lzSg4eFhScqZ9Shk+vTp6unp0YQJExxnUOBNJpkysxQe/ozDx59x+PgzDl+9/BmbpqnXX39d06dPL3pvaMWqTz31lJ555hmdd955OuWUU/Tyyy/r61//us4880xPsyGSNGbMmKJJCt41NjbW9P/x44A/4/DxZxw+/ozDVw9/xsWWZDJCK1YdP368Ojs7df755+td73qXrrjiCv3lX/6ltm7dqoaGhrA+FgAAVJHQZkTe+9736uc//3lYbw8AAGoAZ83UgYaGBq1cuZKZqBDxZxw+/ozDx59x+PgztqtoZ1UAAIBszIgAAIDIEEQAAEBkCCIAACAyBBEAABAZgkid2b17t6644gqdccYZOumkk3TmmWdq5cqVOnr0aNRDqxmrV6/W3LlzNX78eJ188slRD6dm3H777WptbdW4ceM0Z84cPf3001EPqWY8/vjj+sQnPqHp06fLMAw99NBDUQ+p5qxZs0ZnnXWWJkyYoClTpmjBggV66aWXoh5WLBBE6syOHTs0PDysO++8Uy+++KLWrl2rH/zgB7rhhhuiHlrNOHr0qBYtWqTPfe5zUQ+lZmzatEnLli3TypUr9fzzz2vWrFn62Mc+ptdeey3qodWEw4cPa9asWbr99tujHkrN2rp1q5YsWaInn3xSjz76qN566y199KMf1eHDh6MeWuTYvgvdfPPN+v73v6/f//73UQ+lptxzzz1aunSpDh06FPVQqt6cOXN01lln6bbbbpNknVvV0tKia6+9VsuXL494dLXFMAw9+OCDWrBgQdRDqWl9fX2aMmWKtm7dqg996ENRDydSzIhAAwMDmjhxYtTDABwdPXpUzz33nObNmzd6bcyYMZo3b56eeOKJCEcGlG5gYECS+G+vCCJ1b+fOnbr11lv193//91EPBXB04MABpdNpTZ06Nef61KlTtX///ohGBZRueHhYS5cu1Qc/+EG95z3viXo4kSOI1Ijly5fLMIyCXzt27Mh5TW9vry644AItWrRIV155ZUQjrw6l/PkCgJMlS5bohRde0H333Rf1UGIhtEPvUFlf+MIXdNlllxW8Z+bMmaP/vHfvXnV0dGju3Lm66667Qh5d9fP754vgTJ48WYlEQq+++mrO9VdffVWnnnpqRKMCSnPNNdfokUce0eOPP65kMhn1cGKBIFIjmpub1dzc7One3t5edXR0aPbs2br77rs1ZgwTY8X4+fNFsMaOHavZs2dry5YtowWUw8PD2rJli6655ppoBwd4ZJqmrr32Wj344IPq7u7WGWecEfWQYoMgUmd6e3vV3t6u008/Xbfccov6+vpGf8ffLoOxZ88e9ff3a8+ePUqn09q+fbsk6R3veIfe/va3Rzu4KrVs2TJdeuml+qu/+iudffbZWrdunQ4fPqzLL7886qHVhDfeeEM7d+4c/XnXrl3avn27Jk6cqBkzZkQ4stqxZMkSbdiwQQ8//LAmTJgwWt/U1NSkk046KeLRRcxEXbn77rtNSY5fCMall17q+Ofb1dUV9dCq2q233mrOmDHDHDt2rHn22WebTz75ZNRDqhldXV2O/5+99NJLox5azXD77+7dd98d9dAiRx8RAAAQGYoDAABAZAgiAAAgMgQRAAAQGYIIAACIDEEEAABEhiACAAAiQxABAACRIYgAAIDIEEQAAEBkCCIAACAyBBEAABAZgggAAIjM/wcnmRnWQAQXNAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs = 50\n",
        "for epoch in tqdm.tqdm(range(epochs)):\n",
        "    \n",
        "  # forward now is == to calling the model\n",
        "  y_pred = model(x)\n",
        "\n",
        "  # compute loss for all the batch\n",
        "  l   = loss(input = y_pred, target = y)\n",
        "\n",
        "  # compute the gradients for each w_i : dloss/dw_i (usa grafo computacional y almacena ,en el tensor .grad asociado a cada parametro, el valor del gradiente que luego usa el algoritmo de optimizacion)\n",
        "  l.backward()\n",
        "\n",
        "  # paso del optimizer (en este caso un simple SGD) equivale a lo que haciamos a mano de w += -lr*w.grad\n",
        "  optimizer.step()\n",
        "  \n",
        "  # restore or eliminate the grads inside parameter.grad tensor for next iteration\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch % 50 == 0:\n",
        "    print(f\"epoch : {epoch}\")\n",
        "    print(f\"loss : {l.item():.3f}\")\n",
        "    print(f\"w : {model.get_parameter(target = 'linear.weight').item():.3f}\")\n",
        "\n",
        "# try prediction \n",
        "# IMPORTANT TO DETACH \n",
        "prediction = model(x = torch.tensor([[5],[6]], dtype = torch.float32)).detach()\n",
        "print(f\"Predictions :{prediction}\")\n",
        "\n",
        "# plotting\n",
        "y_pred_train = model(x = x).detach().numpy()\n",
        "plt.plot(x_numpy_std, y_numpy_std, 'ro')\n",
        "#plt.plot(x_numpy, y_numpy, 'yo')\n",
        "plt.plot(x_numpy_std, y_pred_train, 'b')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TORCH METHOD 6  : FFN MULTICLASS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:03<00:00, 2618149.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 262009.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 1871203.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# hyperparameters \n",
        "input_size = 784 # 28x28 images\n",
        "hidden_size = 100\n",
        "num_clases = 10\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "lr = 0.001\n",
        "\n",
        "# MNIST\n",
        "train_set = torchvision.datasets.MNIST(root = './data', train = True, transform =transforms.ToTensor() , download = True)\n",
        "test_set = torchvision.datasets.MNIST(root = './data', train = False, transform =transforms.ToTensor() , download = True)\n",
        "\n",
        "# MNIST dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_set, batch_size = batch_size, shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_set, batch_size = batch_size, shuffle = False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: ./data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "Dataset MNIST\n",
            "    Number of datapoints: 10000\n",
            "    Root location: ./data\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n"
          ]
        }
      ],
      "source": [
        "print(train_set)\n",
        "print(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "nLuoTVEkKzT3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cuda available:  False\n",
            "\n",
            "\n",
            "\n",
            "Module : NeuralNet(\n",
            "  (l_1): Linear(in_features=784, out_features=100, bias=True)\n",
            "  (Relu): ReLU()\n",
            "  (l_2): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n",
            "\n",
            "Module : Linear(in_features=784, out_features=100, bias=True)\n",
            "\n",
            "Module : ReLU()\n",
            "\n",
            "Module : Linear(in_features=100, out_features=10, bias=True)\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# data samples shape\n",
        "\n",
        "# custom class model (linear regression layer)\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size,hidden_size, num_classes) -> None:\n",
        "       super().__init__()\n",
        "       self.in_size = input_size\n",
        "       self.hidden = hidden_size\n",
        "       self.num_classes = num_classes\n",
        "       \n",
        "       # Arquitecture of FFN\n",
        "       self.l_1 = nn.Linear(in_features= self.in_size, out_features = self.hidden, bias = True)\n",
        "       self.Relu = nn.ReLU()\n",
        "       self.l_2 = nn.Linear(in_features=  self.hidden, out_features = self.num_classes, bias = True)\n",
        "       \n",
        "    def forward(self,x):\n",
        "        return self.l_2(self.Relu(self.l_1(x)))\n",
        "    \n",
        "\n",
        "# instanciar capa y crear modelo\n",
        "model = NeuralNet(input_size =input_size ,hidden_size = hidden_size, num_classes = num_clases)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Cuda available: \",torch.cuda.is_available())\n",
        "model.to(device)\n",
        "# loss class\n",
        "loss = nn.CrossEntropyLoss()\n",
        "# crea optimizer para prescendir de actualizacion de pesos a mano\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08)\n",
        "\n",
        "# MODULE CLASS DOCU:\n",
        "\"\"\"nn.Module :\n",
        "Base class for all neural network modules.\n",
        "\n",
        "Your models should also subclass this class.\n",
        "\n",
        "Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes: \n",
        "self.sub_module = nn.Linear(...)\"\"\"\n",
        "\n",
        "# Iterate along all de modules inside a network class or model class. Notice that LinearRegression module has inside a linear layer \"module\" or only linear layer\n",
        "# note that the atribute name : self.linear will define the string \"linear\" to refer to that layer inside a module\n",
        "# this will be useful when ,inside a class module, there are several layers\n",
        "print(\"\\n\")\n",
        "\n",
        "for m in model.modules():\n",
        "    print(f\"\\nModule : {m}\")\n",
        "\n",
        "# iterate along all the parameters inside a module ( a module can have a lot of layers with their parameters)\n",
        "for p in model.named_parameters(prefix='', recurse=True, remove_duplicate=True):\n",
        "    #print(f\"\\nParameter : {p}\")\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2neB6EJOLhpB",
        "outputId": "46ce8dd7-b529-4b84-f56c-6d5228a437f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 1/10 [00:13<02:00, 13.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 0\n",
            "loss : 0.270\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 2/10 [00:38<02:42, 20.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 1\n",
            "loss : 0.140\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 3/10 [00:52<02:01, 17.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 2\n",
            "loss : 0.167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 4/10 [01:06<01:35, 15.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 3\n",
            "loss : 0.107\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 5/10 [01:19<01:15, 15.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 4\n",
            "loss : 0.029\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 6/10 [01:33<00:58, 14.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 5\n",
            "loss : 0.103\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 7/10 [01:46<00:42, 14.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 6\n",
            "loss : 0.032\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 8/10 [02:00<00:28, 14.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 7\n",
            "loss : 0.031\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 9/10 [02:14<00:14, 14.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 8\n",
            "loss : 0.028\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [02:27<00:00, 14.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 9\n",
            "loss : 0.032\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "for epoch in tqdm.tqdm(range(epochs)):\n",
        "  for i ,(b_samples ,b_labels) in enumerate(train_loader):\n",
        "    # (100,1,28,28) -> (100, 28*28)\n",
        "    b_samples = b_samples.view(100,28*28).to(device)\n",
        "    #print(b_samples.shape)\n",
        "    # (100) -> (100,1)\n",
        "    b_labels = b_labels.to(device)\n",
        "    \n",
        "    # forward now is == to calling the model\n",
        "    \n",
        "    y_pred = model(b_samples)\n",
        "    #print(y_pred.shape) # (100,10)\n",
        "\n",
        "    # compute loss for all the batch\n",
        "    l   = loss(input = y_pred, target = b_labels) # b_labels debe ser (100) pq crossentropyloss en torch solo necesita el indice de la label no el vector de dimendion 10 entero tipo one hot\n",
        "\n",
        "    # compute the gradients for each w_i : dloss/dw_i (usa grafo computacional y almacena ,en el tensor .grad asociado a cada parametro, el valor del gradiente que luego usa el algoritmo de optimizacion)\n",
        "    l.backward()\n",
        "\n",
        "    # paso del optimizer (en este caso un simple SGD) equivale a lo que haciamos a mano de w += -lr*w.grad\n",
        "    optimizer.step()\n",
        "    \n",
        "    # restore or eliminate the grads inside parameter.grad tensor for next iteration\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  print(f\"epoch : {epoch}\")\n",
        "  print(f\"loss : {l.item():.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuarcy 1 for iter/batch 0 : 99\n",
            "Accuarcy 2 for iter/batch 0 : 99\n",
            "Accuarcy 1 for iter/batch 1 : 97\n",
            "Accuarcy 2 for iter/batch 1 : 97\n",
            "Accuarcy 1 for iter/batch 2 : 97\n",
            "Accuarcy 2 for iter/batch 2 : 97\n",
            "Accuarcy 1 for iter/batch 3 : 97\n",
            "Accuarcy 2 for iter/batch 3 : 97\n",
            "Accuarcy 1 for iter/batch 4 : 97\n",
            "Accuarcy 2 for iter/batch 4 : 97\n",
            "Accuarcy 1 for iter/batch 5 : 99\n",
            "Accuarcy 2 for iter/batch 5 : 99\n",
            "Accuarcy 1 for iter/batch 6 : 96\n",
            "Accuarcy 2 for iter/batch 6 : 96\n",
            "Accuarcy 1 for iter/batch 7 : 96\n",
            "Accuarcy 2 for iter/batch 7 : 96\n",
            "Accuarcy 1 for iter/batch 8 : 98\n",
            "Accuarcy 2 for iter/batch 8 : 98\n",
            "Accuarcy 1 for iter/batch 9 : 96\n",
            "Accuarcy 2 for iter/batch 9 : 96\n",
            "Accuarcy 1 for iter/batch 10 : 96\n",
            "Accuarcy 2 for iter/batch 10 : 96\n",
            "Accuarcy 1 for iter/batch 11 : 94\n",
            "Accuarcy 2 for iter/batch 11 : 94\n",
            "Accuarcy 1 for iter/batch 12 : 93\n",
            "Accuarcy 2 for iter/batch 12 : 93\n",
            "Accuarcy 1 for iter/batch 13 : 97\n",
            "Accuarcy 2 for iter/batch 13 : 97\n",
            "Accuarcy 1 for iter/batch 14 : 100\n",
            "Accuarcy 2 for iter/batch 14 : 100\n",
            "Accuarcy 1 for iter/batch 15 : 95\n",
            "Accuarcy 2 for iter/batch 15 : 95\n",
            "Accuarcy 1 for iter/batch 16 : 97\n",
            "Accuarcy 2 for iter/batch 16 : 97\n",
            "Accuarcy 1 for iter/batch 17 : 96\n",
            "Accuarcy 2 for iter/batch 17 : 96\n",
            "Accuarcy 1 for iter/batch 18 : 97\n",
            "Accuarcy 2 for iter/batch 18 : 97\n",
            "Accuarcy 1 for iter/batch 19 : 96\n",
            "Accuarcy 2 for iter/batch 19 : 96\n",
            "Accuarcy 1 for iter/batch 20 : 92\n",
            "Accuarcy 2 for iter/batch 20 : 92\n",
            "Accuarcy 1 for iter/batch 21 : 94\n",
            "Accuarcy 2 for iter/batch 21 : 94\n",
            "Accuarcy 1 for iter/batch 22 : 96\n",
            "Accuarcy 2 for iter/batch 22 : 96\n",
            "Accuarcy 1 for iter/batch 23 : 97\n",
            "Accuarcy 2 for iter/batch 23 : 97\n",
            "Accuarcy 1 for iter/batch 24 : 96\n",
            "Accuarcy 2 for iter/batch 24 : 96\n",
            "Accuarcy 1 for iter/batch 25 : 99\n",
            "Accuarcy 2 for iter/batch 25 : 99\n",
            "Accuarcy 1 for iter/batch 26 : 96\n",
            "Accuarcy 2 for iter/batch 26 : 96\n",
            "Accuarcy 1 for iter/batch 27 : 100\n",
            "Accuarcy 2 for iter/batch 27 : 100\n",
            "Accuarcy 1 for iter/batch 28 : 97\n",
            "Accuarcy 2 for iter/batch 28 : 97\n",
            "Accuarcy 1 for iter/batch 29 : 95\n",
            "Accuarcy 2 for iter/batch 29 : 95\n",
            "Accuarcy 1 for iter/batch 30 : 99\n",
            "Accuarcy 2 for iter/batch 30 : 99\n",
            "Accuarcy 1 for iter/batch 31 : 98\n",
            "Accuarcy 2 for iter/batch 31 : 98\n",
            "Accuarcy 1 for iter/batch 32 : 99\n",
            "Accuarcy 2 for iter/batch 32 : 99\n",
            "Accuarcy 1 for iter/batch 33 : 100\n",
            "Accuarcy 2 for iter/batch 33 : 100\n",
            "Accuarcy 1 for iter/batch 34 : 97\n",
            "Accuarcy 2 for iter/batch 34 : 97\n",
            "Accuarcy 1 for iter/batch 35 : 92\n",
            "Accuarcy 2 for iter/batch 35 : 92\n",
            "Accuarcy 1 for iter/batch 36 : 96\n",
            "Accuarcy 2 for iter/batch 36 : 96\n",
            "Accuarcy 1 for iter/batch 37 : 93\n",
            "Accuarcy 2 for iter/batch 37 : 93\n",
            "Accuarcy 1 for iter/batch 38 : 96\n",
            "Accuarcy 2 for iter/batch 38 : 96\n",
            "Accuarcy 1 for iter/batch 39 : 96\n",
            "Accuarcy 2 for iter/batch 39 : 96\n",
            "Accuarcy 1 for iter/batch 40 : 96\n",
            "Accuarcy 2 for iter/batch 40 : 96\n",
            "Accuarcy 1 for iter/batch 41 : 98\n",
            "Accuarcy 2 for iter/batch 41 : 98\n",
            "Accuarcy 1 for iter/batch 42 : 95\n",
            "Accuarcy 2 for iter/batch 42 : 95\n",
            "Accuarcy 1 for iter/batch 43 : 95\n",
            "Accuarcy 2 for iter/batch 43 : 95\n",
            "Accuarcy 1 for iter/batch 44 : 96\n",
            "Accuarcy 2 for iter/batch 44 : 96\n",
            "Accuarcy 1 for iter/batch 45 : 98\n",
            "Accuarcy 2 for iter/batch 45 : 98\n",
            "Accuarcy 1 for iter/batch 46 : 99\n",
            "Accuarcy 2 for iter/batch 46 : 99\n",
            "Accuarcy 1 for iter/batch 47 : 100\n",
            "Accuarcy 2 for iter/batch 47 : 100\n",
            "Accuarcy 1 for iter/batch 48 : 95\n",
            "Accuarcy 2 for iter/batch 48 : 95\n",
            "Accuarcy 1 for iter/batch 49 : 97\n",
            "Accuarcy 2 for iter/batch 49 : 97\n",
            "Accuarcy 1 for iter/batch 50 : 99\n",
            "Accuarcy 2 for iter/batch 50 : 99\n",
            "Accuarcy 1 for iter/batch 51 : 98\n",
            "Accuarcy 2 for iter/batch 51 : 98\n",
            "Accuarcy 1 for iter/batch 52 : 100\n",
            "Accuarcy 2 for iter/batch 52 : 100\n",
            "Accuarcy 1 for iter/batch 53 : 99\n",
            "Accuarcy 2 for iter/batch 53 : 99\n",
            "Accuarcy 1 for iter/batch 54 : 98\n",
            "Accuarcy 2 for iter/batch 54 : 98\n",
            "Accuarcy 1 for iter/batch 55 : 100\n",
            "Accuarcy 2 for iter/batch 55 : 100\n",
            "Accuarcy 1 for iter/batch 56 : 97\n",
            "Accuarcy 2 for iter/batch 56 : 97\n",
            "Accuarcy 1 for iter/batch 57 : 98\n",
            "Accuarcy 2 for iter/batch 57 : 98\n",
            "Accuarcy 1 for iter/batch 58 : 97\n",
            "Accuarcy 2 for iter/batch 58 : 97\n",
            "Accuarcy 1 for iter/batch 59 : 92\n",
            "Accuarcy 2 for iter/batch 59 : 92\n",
            "Accuarcy 1 for iter/batch 60 : 98\n",
            "Accuarcy 2 for iter/batch 60 : 98\n",
            "Accuarcy 1 for iter/batch 61 : 99\n",
            "Accuarcy 2 for iter/batch 61 : 99\n",
            "Accuarcy 1 for iter/batch 62 : 100\n",
            "Accuarcy 2 for iter/batch 62 : 100\n",
            "Accuarcy 1 for iter/batch 63 : 99\n",
            "Accuarcy 2 for iter/batch 63 : 99\n",
            "Accuarcy 1 for iter/batch 64 : 98\n",
            "Accuarcy 2 for iter/batch 64 : 98\n",
            "Accuarcy 1 for iter/batch 65 : 93\n",
            "Accuarcy 2 for iter/batch 65 : 93\n",
            "Accuarcy 1 for iter/batch 66 : 99\n",
            "Accuarcy 2 for iter/batch 66 : 99\n",
            "Accuarcy 1 for iter/batch 67 : 96\n",
            "Accuarcy 2 for iter/batch 67 : 96\n",
            "Accuarcy 1 for iter/batch 68 : 100\n",
            "Accuarcy 2 for iter/batch 68 : 100\n",
            "Accuarcy 1 for iter/batch 69 : 100\n",
            "Accuarcy 2 for iter/batch 69 : 100\n",
            "Accuarcy 1 for iter/batch 70 : 99\n",
            "Accuarcy 2 for iter/batch 70 : 99\n",
            "Accuarcy 1 for iter/batch 71 : 100\n",
            "Accuarcy 2 for iter/batch 71 : 100\n",
            "Accuarcy 1 for iter/batch 72 : 99\n",
            "Accuarcy 2 for iter/batch 72 : 99\n",
            "Accuarcy 1 for iter/batch 73 : 100\n",
            "Accuarcy 2 for iter/batch 73 : 100\n",
            "Accuarcy 1 for iter/batch 74 : 99\n",
            "Accuarcy 2 for iter/batch 74 : 99\n",
            "Accuarcy 1 for iter/batch 75 : 99\n",
            "Accuarcy 2 for iter/batch 75 : 99\n",
            "Accuarcy 1 for iter/batch 76 : 100\n",
            "Accuarcy 2 for iter/batch 76 : 100\n",
            "Accuarcy 1 for iter/batch 77 : 100\n",
            "Accuarcy 2 for iter/batch 77 : 100\n",
            "Accuarcy 1 for iter/batch 78 : 98\n",
            "Accuarcy 2 for iter/batch 78 : 98\n",
            "Accuarcy 1 for iter/batch 79 : 99\n",
            "Accuarcy 2 for iter/batch 79 : 99\n",
            "Accuarcy 1 for iter/batch 80 : 98\n",
            "Accuarcy 2 for iter/batch 80 : 98\n",
            "Accuarcy 1 for iter/batch 81 : 98\n",
            "Accuarcy 2 for iter/batch 81 : 98\n",
            "Accuarcy 1 for iter/batch 82 : 100\n",
            "Accuarcy 2 for iter/batch 82 : 100\n",
            "Accuarcy 1 for iter/batch 83 : 99\n",
            "Accuarcy 2 for iter/batch 83 : 99\n",
            "Accuarcy 1 for iter/batch 84 : 98\n",
            "Accuarcy 2 for iter/batch 84 : 98\n",
            "Accuarcy 1 for iter/batch 85 : 97\n",
            "Accuarcy 2 for iter/batch 85 : 97\n",
            "Accuarcy 1 for iter/batch 86 : 100\n",
            "Accuarcy 2 for iter/batch 86 : 100\n",
            "Accuarcy 1 for iter/batch 87 : 100\n",
            "Accuarcy 2 for iter/batch 87 : 100\n",
            "Accuarcy 1 for iter/batch 88 : 100\n",
            "Accuarcy 2 for iter/batch 88 : 100\n",
            "Accuarcy 1 for iter/batch 89 : 100\n",
            "Accuarcy 2 for iter/batch 89 : 100\n",
            "Accuarcy 1 for iter/batch 90 : 96\n",
            "Accuarcy 2 for iter/batch 90 : 96\n",
            "Accuarcy 1 for iter/batch 91 : 100\n",
            "Accuarcy 2 for iter/batch 91 : 100\n",
            "Accuarcy 1 for iter/batch 92 : 99\n",
            "Accuarcy 2 for iter/batch 92 : 99\n",
            "Accuarcy 1 for iter/batch 93 : 100\n",
            "Accuarcy 2 for iter/batch 93 : 100\n",
            "Accuarcy 1 for iter/batch 94 : 97\n",
            "Accuarcy 2 for iter/batch 94 : 97\n",
            "Accuarcy 1 for iter/batch 95 : 98\n",
            "Accuarcy 2 for iter/batch 95 : 98\n",
            "Accuarcy 1 for iter/batch 96 : 96\n",
            "Accuarcy 2 for iter/batch 96 : 96\n",
            "Accuarcy 1 for iter/batch 97 : 92\n",
            "Accuarcy 2 for iter/batch 97 : 92\n",
            "Accuarcy 1 for iter/batch 98 : 98\n",
            "Accuarcy 2 for iter/batch 98 : 98\n",
            "Accuarcy 1 for iter/batch 99 : 98\n",
            "Accuarcy 2 for iter/batch 99 : 98\n",
            "Total accuracy 1 : 0.9746999740600586\n",
            "Total accuracy 2: 0.9746999740600586\n"
          ]
        }
      ],
      "source": [
        "# Evaluation / metrics \n",
        "with torch.no_grad():\n",
        "    accuracy = 0\n",
        "    accuracy_2 = 0  \n",
        "    samples = 0\n",
        "    for i, (b_images,b_labels) in enumerate(test_loader):\n",
        "        samples += 100\n",
        "        b_images = b_images.view(100, 28*28)\n",
        "        y_test_pred = model(b_images)\n",
        "        \n",
        "        # Segundo metodo accuracy\n",
        "        _,pred_class_2 = torch.max(y_test_pred ,dim =  1)\n",
        "        accuracy_2 += (pred_class_2 == b_labels).sum()\n",
        "        \n",
        "        # Primer metodo accurcy\n",
        "        pred_class = y_test_pred.argmax(dim = 1)\n",
        "        accuracy += torch.sum(pred_class == b_labels)\n",
        "        print(f\"Accuarcy 1 for iter/batch {i} : {torch.sum(pred_class == b_labels)}\")\n",
        "        print(f\"Accuarcy 2 for iter/batch {i} : {(pred_class_2 == b_labels).sum()}\")\n",
        "\n",
        "\n",
        "    accuracy = accuracy / samples\n",
        "    accuracy_2 = accuracy_2 / samples \n",
        "    print(\"Total accuracy 1 :\", accuracy.item())\n",
        "    print(\"Total accuracy 2:\", accuracy_2.item())\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TORCH : LOGISTIC REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyNsbbhcOxR5",
        "outputId": "d344168f-8c5b-45c1-b866-8a359f4ad548"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(398, 30) (398,) (171, 30) (171,)\n",
            "torch.Size([398, 30]) torch.Size([398]) torch.Size([171, 30]) torch.Size([171])\n",
            "Comprobacion de si Y_std codificado probabilidades o one hot (0/1) tensor([1., 1., 0., 0., 1.])\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# hyperparameters \n",
        "batch_size = 20\n",
        "num_clases = 2\n",
        "num_epochs = 5\n",
        "lr = 0.001\n",
        "\n",
        "# DATA\n",
        "bc = datasets.load_breast_cancer()\n",
        "x,y = bc.data, bc.target\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, train_size = 0.7, test_size = 0.3, random_state = 1234)\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
        "\n",
        "# std\n",
        "sc = StandardScaler()\n",
        "sc.fit(x_train)\n",
        "x_train_std = sc.transform(x_train)\n",
        "x_test_std = sc.transform(x_test)\n",
        "\n",
        "# numpy -> tensor\n",
        "X_train_std = torch.from_numpy(x_train_std.astype(np.float32))\n",
        "Y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "X_test_std = torch.from_numpy(x_test_std.astype(np.float32))\n",
        "Y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "print(X_train_std.shape, Y_train.shape, X_test_std.shape, Y_test.shape)\n",
        "print(f\"Comprobacion de si Y_train codificado probabilidades o one hot (0/1) {Y_train[0:5]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VCjpi0oiL9g",
        "outputId": "82ec7283-dfb7-4fdc-810c-d2c10d398540"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Module : LogisticRegression(\n",
            "  (l_1): Linear(in_features=30, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "Module : Linear(in_features=30, out_features=1, bias=True)\n",
            "\n",
            "Module : Sigmoid()\n",
            "\n",
            "Parameter : ('l_1.weight', Parameter containing:\n",
            "tensor([[ 0.1601, -0.0820,  0.1526,  0.1448,  0.0036,  0.1233, -0.1329,  0.0230,\n",
            "         -0.1475, -0.1721, -0.0149, -0.0316, -0.0733, -0.1319,  0.0361,  0.1575,\n",
            "         -0.1680,  0.1360, -0.1665, -0.1451, -0.1748, -0.1579, -0.1410,  0.1317,\n",
            "          0.0409,  0.0362, -0.0563, -0.1063, -0.1353,  0.0314]],\n",
            "       requires_grad=True))\n",
            "\n",
            "Parameter : ('l_1.bias', Parameter containing:\n",
            "tensor([0.0786], requires_grad=True))\n"
          ]
        }
      ],
      "source": [
        "# model\n",
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self,features, output_size) -> None:\n",
        "        super().__init__()\n",
        "        self.l_1 = nn.Linear(in_features = features, out_features = output_size, bias=True)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self,x):\n",
        "        return self.sigmoid(self.l_1(x))\n",
        "\n",
        "# model object\n",
        "model = LogisticRegression(features = X_train_std.shape[1],output_size = 1)\n",
        "\n",
        "# loss function\n",
        "loss = nn.BCELoss()\n",
        "\n",
        "# optimizer \n",
        "adam = torch.optim.Adam(params = model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08)\n",
        "\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "for m in model.modules():\n",
        "    print(f\"\\nModule : {m}\")\n",
        "\n",
        "# iterate along all the parameters inside a module ( a module can have a lot of layers with their parameters)\n",
        "for p in model.named_parameters(prefix='', recurse=True, remove_duplicate=True):\n",
        "    print(f\"\\nParameter : {p}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUo6snO-ivUr",
        "outputId": "583d06ad-cb10-4341-bc94-dc84755ceb05"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:00<00:00, 85.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "20\n",
            "40\n",
            "60\n",
            "80\n",
            "100\n",
            "120\n",
            "140\n",
            "160\n",
            "180\n",
            "200\n",
            "220\n",
            "240\n",
            "260\n",
            "280\n",
            "300\n",
            "320\n",
            "340\n",
            "360\n",
            "380\n",
            "epoch : 0\n",
            "loss : 0.093\n",
            "0\n",
            "20\n",
            "40\n",
            "60\n",
            "80\n",
            "100\n",
            "120\n",
            "140\n",
            "160\n",
            "180\n",
            "200\n",
            "220\n",
            "240\n",
            "260\n",
            "280\n",
            "300\n",
            "320\n",
            "340\n",
            "360\n",
            "380\n",
            "epoch : 1\n",
            "loss : 0.090\n",
            "0\n",
            "20\n",
            "40\n",
            "60\n",
            "80\n",
            "100\n",
            "120\n",
            "140\n",
            "160\n",
            "180\n",
            "200\n",
            "220\n",
            "240\n",
            "260\n",
            "280\n",
            "300\n",
            "320\n",
            "340\n",
            "360\n",
            "380\n",
            "epoch : 2\n",
            "loss : 0.087\n",
            "0\n",
            "20\n",
            "40\n",
            "60\n",
            "80\n",
            "100\n",
            "120\n",
            "140\n",
            "160\n",
            "180\n",
            "200\n",
            "220\n",
            "240\n",
            "260\n",
            "280\n",
            "300\n",
            "320\n",
            "340\n",
            "360\n",
            "380\n",
            "epoch : 3\n",
            "loss : 0.084\n",
            "0\n",
            "20\n",
            "40\n",
            "60\n",
            "80\n",
            "100\n",
            "120\n",
            "140\n",
            "160\n",
            "180\n",
            "200\n",
            "220\n",
            "240\n",
            "260\n",
            "280\n",
            "300\n",
            "320\n",
            "340\n",
            "360\n",
            "380\n",
            "epoch : 4\n",
            "loss : 0.081\n",
            "Predictions :tensor([[4.5543],\n",
            "        [5.5050]])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for epoch in tqdm.tqdm(range(num_epochs)):\n",
        "  for i in range(0,X_train_std.shape[0],batch_size):\n",
        "    print(i)\n",
        "    if batch_size+i >  X_train_std.shape[0]:\n",
        "      last_index = X_train_std.shape[0]\n",
        "      b_samples =  X_train_std.shape[0]  - i \n",
        "    else:\n",
        "      last_index = batch_size + i\n",
        "      b_samples = batch_size\n",
        "      \n",
        "    b_x = X_train_std[i:last_index,:]\n",
        "    b_y = Y_train[i:last_index]\n",
        "\n",
        "    # forward\n",
        "    y_pred = model(b_x).view(b_samples)\n",
        "    \n",
        "\n",
        "    # loss == computar grafo computacional de la funcion perdida hacia atras para despues calcular gradientes de forma efectiva\n",
        "    l = loss(input = y_pred, target = b_y)\n",
        "    \n",
        "    # backwardpropa == calculo de gradientes de loss respecto pesos y alamacena en tensor .grad asociado a tensor de parametros\n",
        "    l.backward()\n",
        "    \n",
        "    # paso del optimizer == recoge gradientes calculados (dentro de tensor parameters.grad ) y actualiza pesos en funcion algoritmo de optimizacion elegido\n",
        "    adam.step()\n",
        "    \n",
        "    # borrado de gradientes dentro del tensor\n",
        "    adam.zero_grad()\n",
        "    \n",
        "  print(f\"epoch : {epoch}\")\n",
        "  print(f\"loss : {l.item():.3f}\")\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([171, 1])\n",
            "Total accuracy 1 : 0.9181286692619324\n",
            "Total accuracy 2 : 0.9181286692619324\n"
          ]
        }
      ],
      "source": [
        "# Evaluation / metrics \n",
        "with torch.no_grad():\n",
        "    samples = 0\n",
        "    y_test_pred_proba = model(X_test_std)\n",
        "    print(y_test_pred.shape)\n",
        "    \n",
        "    # Establece umbral de ser o no de la clase 1 en funcion de probabilidad; recuerda que y_pred son las probabilidades de pertenecer a clase 1\n",
        "    # es decir se transforma el tensor de probabilidad en un tensor de prediccion de clase 0 o 1\n",
        "    threshold = 0.5\n",
        "    \n",
        "    # forma 1\n",
        "    y_test_pred_class = torch.tensor([1 if prob_i > threshold else 0 for prob_i in y_test_pred_proba], dtype = torch.int)\n",
        "    \n",
        "    # forma 2\n",
        "    y_test_pred_class_2 = torch.zeros(y_test_pred_proba.shape[0])\n",
        "    for i,y_i in enumerate(y_test_pred.view(y_test_pred_proba.shape[0])):\n",
        "        if y_i.item() > threshold:\n",
        "            y_test_pred_class_2[i] = 1\n",
        "        else:\n",
        "            y_test_pred_class_2[i] = 0\n",
        "    \n",
        "    # Metodo accuracy\n",
        "    accuracy = torch.sum(y_test_pred_class == Y_test) / X_test_std.shape[0]\n",
        "    accuracy_2 = torch.sum(y_test_pred_class_2 == Y_test) / X_test_std.shape[0]\n",
        "    \n",
        "    \n",
        "    print(\"Total accuracy 1 :\", accuracy.item())\n",
        "    print(\"Total accuracy 2 :\", accuracy_2.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR2omUf6SKDv",
        "outputId": "375a404b-050b-400c-a16b-306317fd8063"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.2999)\n",
            "tensor(0.7001)\n",
            "tensor(1.0000)\n"
          ]
        }
      ],
      "source": [
        "# Evaluation / metrics \n",
        "with torch.no_grad():\n",
        "    accuracy = 0\n",
        "    accuracy_2 = 0  \n",
        "    samples = 0\n",
        "    for i, (b_images,b_labels) in enumerate(test_loader):\n",
        "        samples += 100\n",
        "        b_images = b_images.view(100, 28*28)\n",
        "        y_test_pred = model(b_images)\n",
        "        \n",
        "        # Segundo metodo accuracy\n",
        "        _,pred_class_2 = torch.max(y_test_pred ,dim =  1)\n",
        "        accuracy_2 += (pred_class_2 == b_labels).sum()\n",
        "        \n",
        "        # Primer metodo accurcy\n",
        "        pred_class = y_test_pred.argmax(dim = 1)\n",
        "        accuracy += torch.sum(pred_class == b_labels)\n",
        "        print(f\"Accuarcy 1 for iter/batch {i} : {torch.sum(pred_class == b_labels)}\")\n",
        "        print(f\"Accuarcy 2 for iter/batch {i} : {(pred_class_2 == b_labels).sum()}\")\n",
        "\n",
        "\n",
        "    accuracy = accuracy / samples\n",
        "    accuracy_2 = accuracy_2 / samples \n",
        "    print(\"Total accuracy 1 :\", accuracy.item())\n",
        "    print(\"Total accuracy 2:\", accuracy_2.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nKRFw4CTR9U",
        "outputId": "9fc254d9-ecc5-4619-e50f-d1aceb29dd70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.7001)\n",
            "tensor(0.2779)\n",
            "tensor(0.9779)\n"
          ]
        }
      ],
      "source": [
        "suma = 0\n",
        "for e in x_soft_max[1,:]:\n",
        "  print(e)\n",
        "  suma += e\n",
        "print(suma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXLp1WB3F_iI",
        "outputId": "08dad541-a023-4fe0-8394-8b900a6a429f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[ 0.5207, -1.2700,  0.9622, -1.4488],\n",
            "          [-0.3503, -1.8362, -0.2652,  1.5133],\n",
            "          [-0.5715, -1.1178, -0.0886, -0.9020]],\n",
            "\n",
            "         [[-0.2685,  1.1808, -0.2541,  0.6832],\n",
            "          [ 0.6094, -0.1029, -0.8680,  0.7459],\n",
            "          [ 0.1279, -0.4754,  0.0697, -1.5372]]]])\n",
            "tensor([[[[ 0.5207, -1.2700,  0.9622, -1.4488],\n",
            "          [-0.2685,  1.1808, -0.2541,  0.6832]],\n",
            "\n",
            "         [[-0.3503, -1.8362, -0.2652,  1.5133],\n",
            "          [ 0.6094, -0.1029, -0.8680,  0.7459]],\n",
            "\n",
            "         [[-0.5715, -1.1178, -0.0886, -0.9020],\n",
            "          [ 0.1279, -0.4754,  0.0697, -1.5372]]]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.randn(1, 2, 3, 4)\n",
        "a.size()\n",
        "print(a)\n",
        "b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
        "b.size()\n",
        "print(b)\n",
        "c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
        "c.size()\n",
        "torch.equal(b, c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gW5MjPReZLhY"
      },
      "outputs": [],
      "source": [
        "# Red estilo pytorch\n",
        "class FFNN(torch.nn.Module):\n",
        "  def __init__(self, d0=300, d1=200, d2=300, d3 = 3):\n",
        "    super(FFNN, self).__init__()\n",
        "\n",
        "    # Definimos capas (automáticamente se registran como parametros)\n",
        "    self.fc1 = torch.nn.Linear(d0, d1, bias=True)\n",
        "    self.fc2 = torch.nn.Linear(d1, d2, bias=True)\n",
        "    self.fc3 = torch.nn.Linear(d2,  d3, bias=True)\n",
        "\n",
        "  # Computa la pasada hacia adelante\n",
        "  def forward(self, x):\n",
        "\n",
        "    u1 = self.fc1(x)\n",
        "    h1 = torch.tanh(u1)\n",
        "    u2 = self.fc2(h1)\n",
        "    h2 = torch.sigmoid(u2)\n",
        "    u3 = self.fc3(h2)\n",
        "    _sft_max_last = torch.nn.Softmax(dim = 1)\n",
        "    y_pred = _sft_max_last(u3)\n",
        "\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ui-y_i-UR1Rz"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class RandomDataSet(Dataset):\n",
        "  def __init__(self, N, f, k):\n",
        "    R_N_f = torch.rand(N,f)\n",
        "    self.X = torch.bernoulli(R_N_f)\n",
        "    R_N_1 = torch.rand(N,k)\n",
        "    #self.Y = torch.bernoulli(R_N_1)\n",
        "    _sftmax = torch.nn.Softmax(dim=1)\n",
        "    self.Y  = _sftmax(R_N_1)\n",
        "    self.num_features = f\n",
        "\n",
        "  # Debemos definir __len__ para retornar el tamaño del dataset\n",
        "  def __len__(self):\n",
        "    return self.X.size()[0]\n",
        "\n",
        "  # Debemos definir __getitem__ para retornar el i-ésimo\n",
        "  # ejemplo en nuestro dataset.\n",
        "  def __getitem__(self, i):\n",
        "    return self.X[i], self.Y[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sh96-3s-ZjSL"
      },
      "outputs": [],
      "source": [
        "\n",
        "def loop_FFNN(dataset, batch_size, d1, d2, d3, lr,\n",
        "                 epochs, run_in_GPU=True, reports_every=1,\n",
        "                 cheq_grad=False):\n",
        "\n",
        "  # Define un tipo para los tensores según si correrá en la GPU o no\n",
        "  device = 'cuda' if run_in_GPU else 'cpu'\n",
        "\n",
        "  # d0 es la cantidad de features\n",
        "  d0 = dataset.num_features\n",
        "\n",
        "  # Crea la red\n",
        "  red = FFNN(d0, d1, d2, d3)\n",
        "\n",
        "  # Pasa la red al dispositivo elegido\n",
        "  red.to(device)\n",
        "\n",
        "  # Muestra la cantidad de parámetros\n",
        "  print('Red:', red)\n",
        "\n",
        "  # Crea un dataloader desde el dataset\n",
        "  data = DataLoader(dataset, batch_size, shuffle=True)\n",
        "\n",
        "  # Crea un optimizador para el descenso de gradiente\n",
        "  optimizador = torch.optim.SGD(red.parameters(), lr)\n",
        "\n",
        "  # Define una perdida\n",
        "  #perdida = torch.nn.BCELoss()\n",
        "  perdida = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  # Comienza el entrenamiento\n",
        "  tiempo_epochs = 0\n",
        "  for e in range(1,epochs+1):\n",
        "    inicio_epoch = time.time()\n",
        "\n",
        "    for (x,y) in data:\n",
        "      # Asegura de pasarlos a la GPU si fuera necesario\n",
        "      x, y = x.to(device), y.to(device)\n",
        "\n",
        "      # Computa la pasada hacia adelante (forward)\n",
        "      y_pred = red.forward(x)\n",
        "\n",
        "      # Computa la función de pérdida\n",
        "      L = perdida(y_pred,y)\n",
        "\n",
        "      # Computa los gradientes hacia atrás (backpropagation)\n",
        "      L.backward()\n",
        "\n",
        "      # Descenso de gradiente para actualizar los parámetros\n",
        "      optimizador.step()\n",
        "\n",
        "      # Limpia los gradientes\n",
        "      optimizador.zero_grad()\n",
        "\n",
        "    tiempo_epochs += time.time() - inicio_epoch\n",
        "\n",
        "    if e % reports_every == 0:\n",
        "      # Calcula la certeza de las predicciones sobre todo el conjunto\n",
        "      X = dataset.X.to(device)\n",
        "      Y = dataset.Y.to(device)\n",
        "\n",
        "      # Predice usando la red\n",
        "      Y_PRED = red.forward(X)\n",
        "\n",
        "      # Calcula la pérdida de todo el conjunto\n",
        "      L_total = perdida(Y_PRED, Y)\n",
        "\n",
        "      # Elige una clase dependiendo del valor de Y_PRED\n",
        "      Y_PRED_BIN = (Y_PRED >= 0.5).float()\n",
        "\n",
        "      correctos = torch.sum(Y_PRED_BIN == Y).item()\n",
        "      acc = (correctos / N) * 100\n",
        "\n",
        "      sys.stdout.write(\n",
        "            '\\rEpoch:{0:03d}'.format(e) + ' Acc:{0:.2f}%'.format(acc)\n",
        "            + ' Loss:{0:.4f}'.format(L_total)\n",
        "            + ' Tiempo/epoch:{0:.3f}s'.format(tiempo_epochs/e))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJx5kndFBhgi"
      },
      "outputs": [],
      "source": [
        "N = 50000 # numero de ejemplos\n",
        "f = 300 # numero de features\n",
        "k = 3 # numero de clases\n",
        "\n",
        "dataset = RandomDataSet(N,f, k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "XgaASdM0FnJ9",
        "outputId": "c90ee3d0-102b-4c15-de36-4afae4d4c658"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Red: FFNN(\n",
            "  (fc1): Linear(in_features=300, out_features=500, bias=True)\n",
            "  (fc2): Linear(in_features=500, out_features=100, bias=True)\n",
            "  (fc3): Linear(in_features=100, out_features=5, bias=True)\n",
            ")\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "0D or 1D target tensor expected, multi-target not supported",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-ea9c0511e6a3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m loop_FFNN(dataset, batch_size=100, d1=500, d2=100, d3 = 5, epochs=epochs,\n\u001b[0m\u001b[1;32m      3\u001b[0m              run_in_GPU=True, lr=0.08)\n",
            "\u001b[0;32m<ipython-input-82-7c8d7fa68919>\u001b[0m in \u001b[0;36mloop_FFNN\u001b[0;34m(dataset, batch_size, d1, d2, d3, lr, epochs, run_in_GPU, reports_every, cheq_grad)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m       \u001b[0;31m# Computa la función de pérdida\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m       \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperdida\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0;31m# Computa los gradientes hacia atrás (backpropagation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1180\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3057\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3058\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3059\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
          ]
        }
      ],
      "source": [
        "epochs = 50\n",
        "loop_FFNN(dataset, batch_size=100, d1=500, d2=100, d3 = 3, epochs=epochs,\n",
        "             run_in_GPU=True, lr=0.08)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rr1JvHD8_VG9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
